"""–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ llama.cpp –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã."""
import sys
from pathlib import Path

def test_llama_cpp_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å llama.cpp."""
    print("=== –ü—Ä–æ–≤–µ—Ä–∫–∞ llama.cpp ===")
    
    try:
        import llama_cpp
        print("llama-cpp-python —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print(f"–í–µ—Ä—Å–∏—è: {llama_cpp.__version__}")
    except ImportError:
        print("llama-cpp-python –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install llama-cpp-python")
        return False
    
    return True

def test_model_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ GGUF –º–æ–¥–µ–ª–∏."""
    print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ ===")
    
    from config import MODELS_DIR, DEFAULT_MODEL_FILENAME
    
    model_path = MODELS_DIR / DEFAULT_MODEL_FILENAME
    print(f"–û–∂–∏–¥–∞–µ–º—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: {model_path}")
    
    if model_path.exists():
        print(f"–ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {model_path.stat().st_size / (1024*1024*1024):.2f} GB")
        return True
    else:
        print(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        print("–ù—É–∂–µ–Ω GGUF —Ñ–∞–π–ª –¥–ª—è llama.cpp")
        
        # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –¥—Ä—É–≥–∏–µ GGUF —Ñ–∞–π–ª—ã
        gguf_files = list(MODELS_DIR.glob("*.gguf"))
        if gguf_files:
            print(f"–ù–∞–π–¥–µ–Ω—ã GGUF —Ñ–∞–π–ª—ã: {[f.name for f in gguf_files]}")
        else:
            print("GGUF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        return False

def test_llama_cpp_loading():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –≤ llama.cpp."""
    print("\n=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ===")
    
    try:
        from llama_cpp import Llama
        from config import MODELS_DIR, DEFAULT_MODEL_FILENAME, DEFAULT_NUM_THREADS, DEFAULT_CONTEXT_LENGTH
        
        model_path = MODELS_DIR / DEFAULT_MODEL_FILENAME
        
        if not model_path.exists():
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç")
            return False
        
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        llm = Llama(
            model_path=str(model_path),
            n_threads=DEFAULT_NUM_THREADS,
            n_ctx=DEFAULT_CONTEXT_LENGTH,
            verbose=False,
        )
        
        print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        print("–¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...")
        response = llm.create_completion(
            prompt="–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
            max_tokens=50,
            temperature=0.7,
        )
        
        generated_text = response["choices"][0]["text"].strip()
        print(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: '{generated_text}'")
        
        return True
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def test_rag_with_llama():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π RAG —Å llama.cpp."""
    print("\n=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG —Å llama.cpp ===")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        from config import CHROMA_DB_DIR
        if not CHROMA_DB_DIR.exists():
            print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é.")
            return False
        
        print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω–∞")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å rag_query.py
        import subprocess
        
        print("–ó–∞–ø—É—Å–∫–∞–µ–º rag_query.py...")
        result = subprocess.run([
            sys.executable, "rag_query.py", 
            "--top-k", "2"
        ], 
        input="–¥–æ–∫–æ–≤–∞–Ω–∏–µ —Å—É–¥–Ω–∞\nexit\n", 
        text=True, 
        capture_output=True, 
        timeout=60
        )
        
        if result.returncode == 0:
            print("RAG —Å llama.cpp —Ä–∞–±–æ—Ç–∞–µ—Ç")
            print("–†–µ–∑—É–ª—å—Ç–∞—Ç:")
            output_lines = result.stdout.split('\n')[:10]
            for line in output_lines:
                if line.strip():
                    print(f"  {line}")
        else:
            print(f"–û—à–∏–±–∫–∞ RAG: {result.stderr}")
            
        return result.returncode == 0
        
    except subprocess.TimeoutExpired:
        print("–¢–∞–π–º–∞—É—Ç RAG —Ç–µ—Å—Ç–∞")
        return False
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ RAG —Ç–µ—Å—Ç–∞: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è llama.cpp."""
    print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ llama.cpp –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å llama.cpp
    if not test_llama_cpp_availability():
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    if not test_model_availability():
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("1. –°–∫–∞—á–∞–π—Ç–µ GGUF –º–æ–¥–µ–ª—å Qwen2.5-7B-Instruct")
        print("2. –ü–æ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É models/")
        print("3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ rag_query_transformers.py –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å transformers")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏
    if not test_llama_cpp_loading():
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π RAG
    test_rag_with_llama()
    
    print("\n" + "=" * 50)
    print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ llama.cpp –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    main()
