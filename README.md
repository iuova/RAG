# RAG (Retrieval-Augmented Generation) Project

Проект для работы с RAG (Retrieval-Augmented Generation) с использованием локальных языковых моделей.

## Описание

Этот проект реализует систему RAG, которая объединяет поиск информации с генерацией текста, используя локальные языковые модели для обработки запросов и генерации ответов.

## Структура проекта

```
RAG/
├── chroma_db/          # База данных ChromaDB для векторного поиска
├── data/              # Данные для индексации
├── llama.cpp/         # Библиотеки и исполняемые файлы llama.cpp
├── models/            # Модели языковых моделей (.gguf файлы)
├── venv/              # Виртуальное окружение Python
├── rag_index.py       # Скрипт для индексации документов
├── rag_query.py       # Скрипт для выполнения запросов
├── requirements.txt  # Зависимости Python
└── README.md          # Этот файл
```

## Возможности

- Индексация документов в векторную базу данных
- Поиск релевантных документов по запросам
- Генерация ответов с использованием локальных LLM
- Поддержка различных форматов документов
- Интеграция с llama.cpp для работы с моделями

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/iuova/RAG.git
cd RAG
```

2. Создайте виртуальное окружение:
```bash
python -m venv venv
```

3. Активируйте виртуальное окружение:
```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

4. Установите зависимости:
```bash
pip install -r requirements.txt
```

## Использование

### Индексация документов
```bash
python rag_index.py
```

### Выполнение запросов
```bash
python rag_query.py
```

## Модели

Проект поддерживает работу с различными языковыми моделями в формате GGUF:
- Meta-Llama-3-8B-Instruct
- CodeLlama-70B-Python
- GPT-OSS-20B

## Требования

- Python 3.8+
- Достаточно места на диске для моделей (несколько GB)
- RAM: рекомендуется 8GB+ для работы с моделями

## Лицензия

Этот проект использует различные лицензии в зависимости от компонентов. См. файлы лицензий в соответствующих директориях.

## Автор

iuova
