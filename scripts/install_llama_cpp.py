"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏ llama-cpp-python –Ω–∞ Windows."""
import subprocess
import sys
import os
from pathlib import Path

def check_visual_studio():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ Visual Studio Build Tools."""
    print("–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Visual Studio Build Tools...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ cl.exe –≤ PATH
    try:
        result = subprocess.run(['cl'], capture_output=True, text=True)
        if result.returncode == 0 or "Microsoft" in result.stderr:
            print("Visual Studio Build Tools –Ω–∞–π–¥–µ–Ω—ã")
            return True
    except FileNotFoundError:
        pass
    
    print("Visual Studio Build Tools –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    return False

def install_build_tools():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Visual Studio Build Tools."""
    print("\n–î–ª—è –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ llama-cpp-python –Ω—É–∂–Ω—ã Visual Studio Build Tools.")
    print("–°–∫–∞—á–∞–π—Ç–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å: https://visualstudio.microsoft.com/visual-cpp-build-tools/")
    print("–í—ã–±–µ—Ä–∏—Ç–µ 'C++ build tools' –≤ —Å–ø–∏—Å–∫–µ —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫.")
    
    choice = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É llama-cpp-python? (y/n): ").lower()
    return choice == 'y'

def install_precompiled():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é."""
    print("\n–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é...")
    
    try:
        # –ü–æ–ø—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–µ—Å–∞–º–∏
        result = subprocess.run([
            sys.executable, "-m", "pip", "install", 
            "llama-cpp-python",
            "--extra-index-url", "https://abetlen.github.io/llama-cpp-python/whl/cpu"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("llama-cpp-python —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            print(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return False

def install_from_source():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞."""
    print("\n–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞...")
    
    try:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CMake –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        subprocess.run([sys.executable, "-m", "pip", "install", "cmake"], check=True)
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º llama-cpp-python
        result = subprocess.run([
            sys.executable, "-m", "pip", "install", 
            "llama-cpp-python", "--no-cache-dir"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ llama-cpp-python —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω –∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return False

def test_installation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É llama-cpp-python."""
    print("\n–¢–µ—Å—Ç–∏—Ä—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É...")
    
    try:
        import llama_cpp
        print(f"‚úÖ llama-cpp-python –≤–µ—Ä—Å–∏—è: {llama_cpp.__version__}")
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞
        from llama_cpp import Llama
        print("‚úÖ –ò–º–ø–æ—Ä—Ç Llama —É—Å–ø–µ—à–µ–Ω")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False

def download_sample_model():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–∫–∞—á–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å."""
    print("\n–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω–∞ GGUF –º–æ–¥–µ–ª—å.")
    print("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏:")
    print("1. Qwen2.5-7B-Instruct (4.1 GB)")
    print("2. Llama 3.1 8B (4.1 GB)")
    print("3. Mistral 7B (4.1 GB)")
    
    choice = input("\n–°–∫–∞—á–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å? (y/n): ").lower()
    if choice == 'y':
        download_model()

def download_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å."""
    print("\n–°–∫–∞—á–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å...")
    
    try:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º huggingface-hub –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        subprocess.run([sys.executable, "-m", "pip", "install", "huggingface-hub"], check=True)
        
        from huggingface_hub import hf_hub_download
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É models –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        model_path = hf_hub_download(
            repo_id="TheBloke/Qwen2.5-7B-Instruct-GGUF",
            filename="qwen2.5-7b-instruct-q4_k_m.gguf",
            local_dir=str(models_dir)
        )
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞: {model_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏."""
    print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ llama-cpp-python –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Python –≤–µ—Ä—Å–∏—é
    if sys.version_info < (3, 8):
        print("–¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.8 –∏–ª–∏ –≤—ã—à–µ")
        return
    
    print(f"Python –≤–µ—Ä—Å–∏—è: {sys.version}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Visual Studio Build Tools
    has_vs = check_visual_studio()
    
    if not has_vs:
        if not install_build_tools():
            print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return
    
    # –ü—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    if install_precompiled():
        if test_installation():
            print("\nüéâ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            download_sample_model()
            return
    
    # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –∫–æ–º–ø–∏–ª—è—Ü–∏—é
    if has_vs:
        print("\n–ü—Ä–æ–±—É–µ–º –∫–æ–º–ø–∏–ª—è—Ü–∏—é –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞...")
        if install_from_source():
            if test_installation():
                print("\nüéâ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                download_sample_model()
                return
    
    print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å llama-cpp-python")
    print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Visual Studio Build Tools")
    print("2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ rag_query_transformers.py –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É")
    print("3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: docs/llama_cpp_installation_guide.md")

if __name__ == "__main__":
    main()
